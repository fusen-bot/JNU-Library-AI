#!/usr/bin/env python3
"""
äº¤äº’äº‹ä»¶ç»Ÿè®¡ç®¡ç†å™¨
ä¸“é—¨è´Ÿè´£å°†äº¤äº’æ•°æ®è¾“å‡ºåˆ°ä¸åŒçš„ç»Ÿè®¡æ–‡ä»¶å¤¹ä¸­
"""

import os
import json
import csv
from datetime import datetime, date
from pathlib import Path
import pandas as pd

class InteractionStatsManager:
    def __init__(self, base_dir="interaction_stats"):
        """
        åˆå§‹åŒ–äº¤äº’ç»Ÿè®¡ç®¡ç†å™¨
        
        Args:
            base_dir (str): ç»Ÿè®¡æ–‡ä»¶çš„åŸºç¡€ç›®å½•
        """
        self.base_dir = Path(base_dir)
        self.ensure_directories()
        
    def ensure_directories(self):
        """ç¡®ä¿æ‰€æœ‰å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        subdirs = [
            'daily',           # æ—¥ç»Ÿè®¡
            'sessions',        # ä¼šè¯ç»Ÿè®¡  
            'search_results',  # æœç´¢ç»“æœç»Ÿè®¡
            'panel_interactions',  # é¢æ¿äº¤äº’ç»Ÿè®¡
            'summary_reports'  # æ€»ç»“æŠ¥å‘Š
        ]
        
        for subdir in subdirs:
            (self.base_dir / subdir).mkdir(parents=True, exist_ok=True)
    
    def save_search_result_stats(self, session_id, user_query, search_data):
        """
        ä¿å­˜æœç´¢ç»“æœç»Ÿè®¡
        
        Args:
            session_id (str): ä¼šè¯ID
            user_query (str): ç”¨æˆ·æŸ¥è¯¢
            search_data (dict): æœç´¢æ•°æ®
        """
        timestamp = datetime.now()
        date_str = timestamp.strftime('%Y-%m-%d')
        time_str = timestamp.strftime('%H-%M-%S')
        
        # æœç´¢ç»“æœæ–‡ä»¶å
        filename = f"search_{date_str}_{time_str}_{session_id[:8]}.json"
        filepath = self.base_dir / 'search_results' / filename
        
        # æ„å»ºæœç´¢ç»“æœæ•°æ®
        result_data = {
            'timestamp': timestamp.isoformat(),
            'session_id': session_id,
            'user_query': user_query,
            'search_stats': search_data,
            'metadata': {
                'file_created': timestamp.isoformat(),
                'data_type': 'search_result'
            }
        }
        
        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š æœç´¢ç»“æœç»Ÿè®¡å·²ä¿å­˜: {filepath}")
        return filepath
    
    def save_panel_interaction_stats(self, session_id, panel_data):
        """
        ä¿å­˜é¢æ¿äº¤äº’ç»Ÿè®¡
        
        Args:
            session_id (str): ä¼šè¯ID
            panel_data (dict): é¢æ¿äº¤äº’æ•°æ®
        """
        timestamp = datetime.now()
        date_str = timestamp.strftime('%Y-%m-%d')
        time_str = timestamp.strftime('%H-%M-%S')
        
        # é¢æ¿äº¤äº’æ–‡ä»¶å
        filename = f"panel_{date_str}_{time_str}_{session_id[:8]}.json"
        filepath = self.base_dir / 'panel_interactions' / filename
        
        # æ„å»ºé¢æ¿äº¤äº’æ•°æ®
        interaction_data = {
            'timestamp': timestamp.isoformat(),
            'session_id': session_id,
            'panel_stats': panel_data,
            'metadata': {
                'file_created': timestamp.isoformat(),
                'data_type': 'panel_interaction'
            }
        }
        
        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(interaction_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“– é¢æ¿äº¤äº’ç»Ÿè®¡å·²ä¿å­˜: {filepath}")
        return filepath
    
    def save_session_summary(self, session_id, session_stats):
        """
        ä¿å­˜ä¼šè¯æ€»ç»“
        
        Args:
            session_id (str): ä¼šè¯ID
            session_stats (dict): ä¼šè¯ç»Ÿè®¡æ•°æ®
        """
        timestamp = datetime.now()
        date_str = timestamp.strftime('%Y-%m-%d')
        time_str = timestamp.strftime('%H-%M-%S')
        
        # ä¼šè¯æ–‡ä»¶å
        filename = f"session_{date_str}_{time_str}_{session_id[:8]}.json"
        filepath = self.base_dir / 'sessions' / filename
        
        # æ„å»ºä¼šè¯æ•°æ®
        session_data = {
            'timestamp': timestamp.isoformat(),
            'session_id': session_id,
            'session_summary': session_stats,
            'metadata': {
                'file_created': timestamp.isoformat(),
                'data_type': 'session_summary'
            }
        }
        
        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(session_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“‹ ä¼šè¯æ€»ç»“å·²ä¿å­˜: {filepath}")
        return filepath
    
    def save_daily_summary(self, target_date=None):
        """
        ç”Ÿæˆå¹¶ä¿å­˜æ—¥ç»Ÿè®¡æ€»ç»“
        
        Args:
            target_date (date): ç›®æ ‡æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
        """
        if target_date is None:
            target_date = date.today()
        
        date_str = target_date.strftime('%Y-%m-%d')
        
        # æ”¶é›†å½“å¤©çš„æ‰€æœ‰ç»Ÿè®¡æ•°æ®
        daily_stats = self._collect_daily_stats(target_date)
        
        # æ—¥ç»Ÿè®¡æ–‡ä»¶å
        filename = f"daily_summary_{date_str}.json"
        filepath = self.base_dir / 'daily' / filename
        
        # æ„å»ºæ—¥ç»Ÿè®¡æ•°æ®
        daily_data = {
            'date': date_str,
            'generated_at': datetime.now().isoformat(),
            'daily_statistics': daily_stats,
            'metadata': {
                'file_created': datetime.now().isoformat(),
                'data_type': 'daily_summary'
            }
        }
        
        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(daily_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“… æ—¥ç»Ÿè®¡æ€»ç»“å·²ä¿å­˜: {filepath}")
        return filepath
    
    def _collect_daily_stats(self, target_date):
        """
        æ”¶é›†æŒ‡å®šæ—¥æœŸçš„ç»Ÿè®¡æ•°æ®
        
        Args:
            target_date (date): ç›®æ ‡æ—¥æœŸ
            
        Returns:
            dict: æ—¥ç»Ÿè®¡æ•°æ®
        """
        date_str = target_date.strftime('%Y-%m-%d')
        
        # ç»Ÿè®¡å½“å¤©çš„æœç´¢ç»“æœ
        search_files = list((self.base_dir / 'search_results').glob(f"search_{date_str}_*.json"))
        panel_files = list((self.base_dir / 'panel_interactions').glob(f"panel_{date_str}_*.json"))
        session_files = list((self.base_dir / 'sessions').glob(f"session_{date_str}_*.json"))
        
        stats = {
            'total_searches': len(search_files),
            'total_panel_interactions': len(panel_files),
            'total_sessions': len(session_files),
            'search_details': [],
            'panel_details': [],
            'session_details': []
        }
        
        # æ”¶é›†æœç´¢è¯¦æƒ…
        total_search_duration = 0
        search_queries = []
        
        for search_file in search_files:
            try:
                with open(search_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    search_stats = data.get('search_stats', {})
                    
                    if 'duration_ms' in search_stats:
                        total_search_duration += search_stats['duration_ms']
                    
                    if data.get('user_query'):
                        search_queries.append(data['user_query'])
                    
                    stats['search_details'].append({
                        'query': data.get('user_query', ''),
                        'duration_ms': search_stats.get('duration_ms', 0),
                        'timestamp': data.get('timestamp', '')
                    })
            except Exception as e:
                print(f"âš ï¸ è¯»å–æœç´¢æ–‡ä»¶å¤±è´¥: {search_file}, é”™è¯¯: {e}")
        
        # æ”¶é›†é¢æ¿äº¤äº’è¯¦æƒ…
        total_panel_duration = 0
        unique_books = set()
        
        for panel_file in panel_files:
            try:
                with open(panel_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    panel_stats = data.get('panel_stats', {})
                    
                    if 'duration_ms' in panel_stats:
                        total_panel_duration += panel_stats['duration_ms']
                    
                    if 'book_title' in panel_stats:
                        unique_books.add(panel_stats['book_title'])
                    
                    stats['panel_details'].append({
                        'book_title': panel_stats.get('book_title', ''),
                        'duration_ms': panel_stats.get('duration_ms', 0),
                        'timestamp': data.get('timestamp', '')
                    })
            except Exception as e:
                print(f"âš ï¸ è¯»å–é¢æ¿æ–‡ä»¶å¤±è´¥: {panel_file}, é”™è¯¯: {e}")
        
        # æ·»åŠ æ±‡æ€»ç»Ÿè®¡
        stats['summary'] = {
            'total_search_duration_ms': total_search_duration,
            'average_search_duration_ms': total_search_duration / len(search_files) if search_files else 0,
            'total_panel_duration_ms': total_panel_duration,
            'unique_books_viewed': len(unique_books),
            'unique_queries': len(set(search_queries))
        }
        
        return stats
    
    def generate_comprehensive_report(self, days=7):
        """
        ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        
        Args:
            days (int): æŠ¥å‘Šè¦†ç›–çš„å¤©æ•°
        """
        timestamp = datetime.now()
        filename = f"comprehensive_report_{timestamp.strftime('%Y-%m-%d_%H-%M-%S')}.json"
        filepath = self.base_dir / 'summary_reports' / filename
        
        # æ”¶é›†å¤šå¤©çš„æ•°æ®
        report_data = {
            'generated_at': timestamp.isoformat(),
            'report_period_days': days,
            'daily_summaries': [],
            'overall_statistics': {}
        }
        
        # ç”Ÿæˆæ¯æ—¥æ€»ç»“
        for i in range(days):
            target_date = date.today() - pd.Timedelta(days=i)
            daily_stats = self._collect_daily_stats(target_date)
            daily_stats['date'] = target_date.strftime('%Y-%m-%d')
            report_data['daily_summaries'].append(daily_stats)
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_searches = sum(day['total_searches'] for day in report_data['daily_summaries'])
        total_sessions = sum(day['total_sessions'] for day in report_data['daily_summaries'])
        total_panels = sum(day['total_panel_interactions'] for day in report_data['daily_summaries'])
        
        report_data['overall_statistics'] = {
            'total_searches': total_searches,
            'total_sessions': total_sessions,
            'total_panel_interactions': total_panels,
            'average_searches_per_day': total_searches / days if days > 0 else 0,
            'average_sessions_per_day': total_sessions / days if days > 0 else 0
        }
        
        # ä¿å­˜æŠ¥å‘Š
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“ˆ ç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ: {filepath}")
        return filepath
    
    def list_files_by_type(self, data_type=None):
        """
        åˆ—å‡ºæŒ‡å®šç±»å‹çš„ç»Ÿè®¡æ–‡ä»¶
        
        Args:
            data_type (str): æ•°æ®ç±»å‹ ('search', 'panel', 'session', 'daily', 'report')
        
        Returns:
            list: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        if data_type == 'search':
            return list((self.base_dir / 'search_results').glob('*.json'))
        elif data_type == 'panel':
            return list((self.base_dir / 'panel_interactions').glob('*.json'))
        elif data_type == 'session':
            return list((self.base_dir / 'sessions').glob('*.json'))
        elif data_type == 'daily':
            return list((self.base_dir / 'daily').glob('*.json'))
        elif data_type == 'report':
            return list((self.base_dir / 'summary_reports').glob('*.json'))
        else:
            # è¿”å›æ‰€æœ‰æ–‡ä»¶
            all_files = []
            for subdir in ['search_results', 'panel_interactions', 'sessions', 'daily', 'summary_reports']:
                all_files.extend((self.base_dir / subdir).glob('*.json'))
            return all_files
    
    def cleanup_old_files(self, days_to_keep=30):
        """
        æ¸…ç†æ—§çš„ç»Ÿè®¡æ–‡ä»¶
        
        Args:
            days_to_keep (int): ä¿ç•™çš„å¤©æ•°
        """
        cutoff_date = datetime.now() - pd.Timedelta(days=days_to_keep)
        deleted_count = 0
        
        for file_path in self.list_files_by_type():
            try:
                file_time = datetime.fromtimestamp(file_path.stat().st_mtime)
                if file_time < cutoff_date:
                    file_path.unlink()
                    deleted_count += 1
                    print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§æ–‡ä»¶: {file_path}")
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
        
        print(f"ğŸ§¹ æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {deleted_count} ä¸ªæ—§æ–‡ä»¶")
        return deleted_count

# åˆ›å»ºå…¨å±€å®ä¾‹
stats_manager = InteractionStatsManager()

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    print("ğŸ“Š äº¤äº’ç»Ÿè®¡ç®¡ç†å™¨æµ‹è¯•")
    
    # æµ‹è¯•æ•°æ®
    test_session_id = "test_session_123"
    test_search_data = {
        "duration_ms": 1500,
        "total_duration_ms": 1500,
        "total_search_count": 1
    }
    test_panel_data = {
        "book_title": "æµ‹è¯•ä¹¦ç±",
        "duration_ms": 2500,
        "panel_total_duration_ms": 2500
    }
    test_session_stats = {
        "searchStats": {"totalCount": 1, "totalDuration": 1500},
        "panelStats": {"totalDuration": 2500, "uniqueBooksViewed": 1}
    }
    
    # ä¿å­˜æµ‹è¯•æ•°æ®
    stats_manager.save_search_result_stats(test_session_id, "æµ‹è¯•æŸ¥è¯¢", test_search_data)
    stats_manager.save_panel_interaction_stats(test_session_id, test_panel_data)
    stats_manager.save_session_summary(test_session_id, test_session_stats)
    
    # ç”Ÿæˆæ—¥ç»Ÿè®¡
    stats_manager.save_daily_summary()
    
    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    stats_manager.generate_comprehensive_report(7)
    
    print("âœ… æµ‹è¯•å®Œæˆï¼")
