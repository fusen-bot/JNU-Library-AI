# 代码修改最佳实践路径

本文档旨在指导后续的代码重构，将系统从一个单一、笼统的LLM调用，转变为一个解耦的、程序化控制与AI生成分离的清晰架构。

## 第一步：梳理新旧逻辑流程（思路对齐）

为了确保我们完全同步，我们先用流程图的形式来对比一下新旧两种工作模式。

### 旧的工作流程（问题所在：缓慢、不可控）

```mermaid
graph TD
    A[用户在前端输入任意检索词] --> B{程序将检索词直接提交给大语言模型API};
    B --> C{大语言模型 (LLM) 同时进行三项工作：<br>1. 理解词义<br>2. 思考并推荐3本书<br>3. 为每本书生成理由};
    C --> D[前端接收并展示一个"随机盲盒"];
```

**核心问题**:
- **高延迟**: LLM需要一次性完成复杂的思考和生成任务，耗时很长。
- **不可控**: 推荐什么书、理由是什么，完全由LLM决定，结果不稳定，像开"盲盒"。
- **高成本**: 每次调用都包含了大量的上下文和生成内容，API费用较高。

### 新的工作流程（优势：快速、可控、经济）

```mermaid
graph TD
    subgraph "第一阶段：程序侧（本地执行，零延迟）"
        A[用户触发一个"标准化的研究任务"] --> B{程序根据任务关键词<br>在本地"实验书库"中进行匹配};
        B --> C[程序瞬间确定了要展示的 A, B, C 三本书];
    end

    subgraph "第二阶段：AI侧（目标明确，快速响应）"
        D(程序向大语言模型API发起三次独立的、轻量的请求) --> E{请求1: "请为A书生成理由"};
        D --> F{请求2: "请为B书生成理由"};
        D --> G{请求3: "请为C书生成理由"};
    end
    
    subgraph "第三阶段：整合与呈现"
        H[程序汇总三次API返回的理由] --> I[前端接收并展示一个<br>完全一致的、受控的界面];
    end
    
    C --> D;
```

**核心优势**:
- **快速响应**: 第一阶段的书籍匹配在本地完成，几乎零延迟。第二阶段的AI调用是并行的、轻量的，总耗时大大缩短。
- **完全可控**: 推荐哪些书籍由我们预先设定的"实验书库"决定，保证了结果的稳定性和质量。
- **经济高效**: 每次AI调用任务单一、上下文简短，显著降低了API成本。

## 第二步：创建"实验书库"与"匹配规则"（已完成✅）

为了实现新流程的第一阶段，我们需要创建一个程序可读的"实验书库"。这个书库将是我们控制书籍推荐的核心。

我已为您创建 `experimental_book_library.py` 文件。它包含一个名为 `BOOK_LIBRARY` 的字典，用于定义"研究任务"与"推荐书籍"之间的映射关系。

**后续开发步骤**:
1. 在 `web_monitor.py` 的 `/api/books_with_reasons` 端点中，导入 `experimental_book_library.py`。
2. 接收到用户查询后，首先调用 `find_books_by_task` 函数，从 `BOOK_LIBRARY` 中匹配并获取预设的书籍列表。
3. 如果匹配成功，则进入下一步（调用AI生成理由）；如果失败，可以提供一个默认的或错误的返回。

## 第三步：编写全新的、解耦后的"提示词"（AI指令）

针对新流程的第二阶段，我们需要一个全新的、为单一本书生成理由的、短小精悍的提示词。这个提示词将取代 `spark.py` 中庞大而复杂的旧版提示词。

**新版系统提示词 (System Prompt)**:

```text
你是江南大学图书馆的资深图书推荐专家。你的任务是为一本指定的书籍生成精准、吸引人的推荐理由。

请严格按照以下JSON格式返回结果，不要包含任何解释性文字，只返回一个完整的JSON对象：

{
  "logical_reason": {
    "user_query_intent": "对用户检索意图的分析",
    "book_core_concepts": ["本书的核心概念1", "本书的核心概念2"],
    "application_fields_match": ["本书与哪些应用领域匹配1", "本书与哪些应用领域匹配2"]
  },
  "social_reason": {
    "departments": [
      {"name": "计算机科学与工程学院", "rate": 0.85},
      {"name": "物联网工程学院", "rate": 0.72},
      {"name": "理学院", "rate": 0.31}
    ]
  }
}
```

**新版用户提示词 (User Prompt)**:

```text
用户检索词是："{user_query}"。请为书籍《{book_title}》（作者：{book_author}）生成推荐理由。
```

**后续开发步骤**:
1. 在 `spark.py` 中，创建一个新的函数，例如 `get_reason_for_single_book(book, user_query)`。
2. 在该函数中，使用上述新版提示词结构来调用LLM API。
3. 在 `web_monitor.py` 中，遍历从"实验书库"获取的书籍列表，为每本书调用这个新的API函数，并最终将所有结果整合后返回给前端。 