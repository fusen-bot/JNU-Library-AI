#!/usr/bin/env python3
"""
äº¤äº’æ—¥å¿—æ•°æ®åˆ†æå·¥å…·
ç”¨äºåˆ†æç”¨æˆ·è¡Œä¸ºæ•°æ®å’Œç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
"""

import pandas as pd
import json
from datetime import datetime
import os

def load_interaction_logs():
    """åŠ è½½äº¤äº’æ—¥å¿—æ•°æ®"""
    if not os.path.exists('interaction_logs.csv'):
        print("âŒ æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ interaction_logs.csv")
        return None
    
    try:
        df = pd.read_csv('interaction_logs.csv')
        print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡æ—¥å¿—è®°å½•")
        return df
    except Exception as e:
        print(f"âŒ åŠ è½½æ—¥å¿—æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None

def analyze_search_performance(df):
    """åˆ†ææœç´¢æ€§èƒ½æ•°æ®"""
    print("\nğŸ” æœç´¢æ€§èƒ½åˆ†æ")
    print("-" * 50)
    
    # æœç´¢å¼€å§‹å’Œç»“æŸè®°å½•
    search_starts = df[df['event_type'] == 'search_start']
    search_ends = df[df['event_type'] == 'search_end']
    
    print(f"ğŸ“Š æœç´¢ä¼šè¯ç»Ÿè®¡:")
    print(f"   æ€»æœç´¢å¼€å§‹æ¬¡æ•°: {len(search_starts)}")
    print(f"   æ€»æœç´¢å®Œæˆæ¬¡æ•°: {len(search_ends)}")
    
    if len(search_ends) > 0:
        # åˆ†ææœç´¢è€—æ—¶ï¼ˆä»session_statsæˆ–å…¶ä»–å­—æ®µï¼‰
        durations = []
        for _, row in search_ends.iterrows():
            if pd.notna(row.get('duration_ms', None)):
                durations.append(row['duration_ms'])
        
        if durations:
            print(f"   å¹³å‡æœç´¢è€—æ—¶: {sum(durations) / len(durations):.1f}ms")
            print(f"   æœ€å¿«æœç´¢: {min(durations)}ms")
            print(f"   æœ€æ…¢æœç´¢: {max(durations)}ms")
    
    # æŒ‰ä¼šè¯åˆ†æ
    sessions = df['session_id'].unique()
    print(f"   æ´»è·ƒä¼šè¯æ•°é‡: {len([s for s in sessions if pd.notna(s)])}")

def analyze_panel_interactions(df):
    """åˆ†ææ‚¬æµ®é¢æ¿äº¤äº’æ•°æ®"""
    print("\nğŸ“– æ‚¬æµ®é¢æ¿äº¤äº’åˆ†æ")
    print("-" * 50)
    
    panel_opens = df[df['event_type'] == 'panel_opened']
    panel_closes = df[df['event_type'] == 'panel_closed']
    
    print(f"ğŸ“Š é¢æ¿äº¤äº’ç»Ÿè®¡:")
    print(f"   é¢æ¿æ‰“å¼€æ¬¡æ•°: {len(panel_opens)}")
    print(f"   é¢æ¿å…³é—­æ¬¡æ•°: {len(panel_closes)}")
    
    # åˆ†æå„ä¹¦ç±çš„å—æ¬¢è¿ç¨‹åº¦
    if len(panel_opens) > 0:
        book_interactions = panel_opens['book_title'].value_counts()
        print(f"\nğŸ“š æœ€å—å…³æ³¨çš„ä¹¦ç±:")
        for i, (book, count) in enumerate(book_interactions.head(5).items(), 1):
            if pd.notna(book):
                print(f"   {i}. {book}: {count}æ¬¡")
    
    # åˆ†æåœç•™æ—¶é•¿
    if len(panel_closes) > 0:
        durations = []
        for _, row in panel_closes.iterrows():
            if pd.notna(row.get('duration_ms', None)):
                durations.append(row['duration_ms'])
        
        if durations:
            print(f"\nâ±ï¸ é¢æ¿åœç•™æ—¶é•¿ç»Ÿè®¡:")
            print(f"   å¹³å‡åœç•™æ—¶é•¿: {sum(durations) / len(durations):.1f}ms")
            print(f"   æœ€çŸ­åœç•™: {min(durations)}ms")
            print(f"   æœ€é•¿åœç•™: {max(durations)}ms")

def analyze_results_display(df):
    """åˆ†æç»“æœé¡µé¢æ˜¾ç¤ºæ•°æ®"""
    print("\nğŸ“„ ç»“æœé¡µé¢åˆ†æ")
    print("-" * 50)
    
    results_shown = df[df['event_type'] == 'results_displayed']
    results_hidden = df[df['event_type'] == 'results_hidden']
    
    print(f"ğŸ“Š ç»“æœé¡µé¢ç»Ÿè®¡:")
    print(f"   ç»“æœæ˜¾ç¤ºæ¬¡æ•°: {len(results_shown)}")
    print(f"   ç»“æœéšè—æ¬¡æ•°: {len(results_hidden)}")
    
    # åˆ†æåœç•™æ—¶é•¿
    if len(results_hidden) > 0:
        durations = []
        for _, row in results_hidden.iterrows():
            if pd.notna(row.get('duration_ms', None)):
                durations.append(row['duration_ms'])
        
        if durations:
            print(f"\nâ±ï¸ ç»“æœé¡µé¢åœç•™æ—¶é•¿:")
            print(f"   å¹³å‡åœç•™æ—¶é•¿: {sum(durations) / len(durations):.1f}ms")
            print(f"   æœ€çŸ­åœç•™: {min(durations)}ms")
            print(f"   æœ€é•¿åœç•™: {max(durations)}ms")

def analyze_session_summaries(df):
    """åˆ†æä¼šè¯æ€»ç»“æ•°æ®"""
    print("\nğŸ“Š ä¼šè¯æ€»ç»“åˆ†æ")
    print("-" * 50)
    
    summaries = df[df['event_type'] == 'session_summary']
    
    if len(summaries) == 0:
        print("   æš‚æ— ä¼šè¯æ€»ç»“æ•°æ®")
        return
    
    print(f"ğŸ“Š ä¼šè¯æ€»ç»“ç»Ÿè®¡:")
    print(f"   ä¼šè¯æ€»ç»“æ•°é‡: {len(summaries)}")
    
    # å°è¯•è§£æä¼šè¯ç»Ÿè®¡æ•°æ®
    total_search_count = 0
    total_search_duration = 0
    total_panel_duration = 0
    unique_books_total = 0
    
    for _, row in summaries.iterrows():
        if pd.notna(row.get('session_stats', None)):
            try:
                stats = json.loads(row['session_stats'])
                search_stats = stats.get('searchStats', {})
                panel_stats = stats.get('panelStats', {})
                
                total_search_count += search_stats.get('totalCount', 0)
                total_search_duration += search_stats.get('totalDuration', 0)
                total_panel_duration += panel_stats.get('totalDuration', 0)
                unique_books_total += panel_stats.get('uniqueBooksViewed', 0)
                
            except json.JSONDecodeError:
                continue
    
    if total_search_count > 0:
        print(f"\nğŸ” èšåˆæœç´¢ç»Ÿè®¡:")
        print(f"   æ€»æœç´¢æ¬¡æ•°: {total_search_count}")
        print(f"   æ€»æœç´¢è€—æ—¶: {total_search_duration}ms")
        print(f"   å¹³å‡æœç´¢è€—æ—¶: {total_search_duration / total_search_count:.1f}ms")
    
    if unique_books_total > 0:
        print(f"\nğŸ“– èšåˆé¢æ¿ç»Ÿè®¡:")
        print(f"   æ€»é¢æ¿åœç•™æ—¶é•¿: {total_panel_duration}ms")
        print(f"   æ€»æŸ¥çœ‹ä¹¦ç±æ•°: {unique_books_total}")

def generate_time_analysis(df):
    """ç”Ÿæˆæ—¶é—´åˆ†æ"""
    print("\nâ° æ—¶é—´åˆ†å¸ƒåˆ†æ")
    print("-" * 50)
    
    # è½¬æ¢æ—¶é—´æˆ³
    df['datetime'] = pd.to_datetime(df['timestamp'], errors='coerce')
    df_with_time = df.dropna(subset=['datetime'])
    
    if len(df_with_time) == 0:
        print("   æ— æœ‰æ•ˆæ—¶é—´æ•°æ®")
        return
    
    # æŒ‰å°æ—¶åˆ†ææ´»åŠ¨
    df_with_time['hour'] = df_with_time['datetime'].dt.hour
    hourly_activity = df_with_time['hour'].value_counts().sort_index()
    
    print("ğŸ“ˆ æŒ‰å°æ—¶æ´»åŠ¨åˆ†å¸ƒ:")
    for hour, count in hourly_activity.head(10).items():
        print(f"   {hour:02d}:00 - {count}æ¬¡äº¤äº’")

def main():
    print("=" * 70)
    print("ğŸ“Š ç”¨æˆ·äº¤äº’è¡Œä¸ºæ—¥å¿—åˆ†ææŠ¥å‘Š")
    print("=" * 70)
    
    # åŠ è½½æ•°æ®
    df = load_interaction_logs()
    if df is None:
        return
    
    print(f"\nğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {df['timestamp'].min()} åˆ° {df['timestamp'].max()}")
    print(f"ğŸ“ˆ æ€»äº¤äº’äº‹ä»¶æ•°: {len(df)}")
    print(f"ğŸ¯ äº‹ä»¶ç±»å‹åˆ†å¸ƒ:")
    event_counts = df['event_type'].value_counts()
    for event_type, count in event_counts.items():
        if pd.notna(event_type):
            print(f"   {event_type}: {count}æ¬¡")
    
    # æ‰§è¡Œå„é¡¹åˆ†æ
    analyze_search_performance(df)
    analyze_panel_interactions(df)
    analyze_results_display(df)
    analyze_session_summaries(df)
    generate_time_analysis(df)
    
    print("\n" + "=" * 70)
    print("âœ¨ åˆ†æå®Œæˆï¼")
    print("ğŸ’¡ æç¤º: å¯ä»¥åŸºäºè¿™äº›æ•°æ®è¿›ä¸€æ­¥ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ")
    print("=" * 70)

if __name__ == "__main__":
    main()
