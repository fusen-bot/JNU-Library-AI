#!/usr/bin/env python3
"""
äº¤äº’ç»Ÿè®¡æ–‡ä»¶æŸ¥çœ‹å·¥å…·
ç”¨äºå¿«é€ŸæŸ¥çœ‹å’Œåˆ†æäº¤äº’ç»Ÿè®¡æ–‡ä»¶å¤¹ä¸­çš„æ•°æ®
"""

import json
import argparse
from pathlib import Path
from datetime import datetime, date
from interaction_stats_manager import stats_manager

def view_latest_files(file_type=None, count=5):
    """æŸ¥çœ‹æœ€æ–°çš„ç»Ÿè®¡æ–‡ä»¶"""
    print(f"ğŸ“Š æœ€æ–°çš„{count}ä¸ª{file_type or 'æ‰€æœ‰ç±»å‹'}ç»Ÿè®¡æ–‡ä»¶:")
    print("-" * 60)
    
    files = stats_manager.list_files_by_type(file_type)
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
    files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
    
    for i, file_path in enumerate(files[:count], 1):
        try:
            mod_time = datetime.fromtimestamp(file_path.stat().st_mtime)
            file_size = file_path.stat().st_size
            
            print(f"{i}. {file_path.name}")
            print(f"   ğŸ“… ä¿®æ”¹æ—¶é—´: {mod_time.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"   ğŸ“¦ æ–‡ä»¶å¤§å°: {file_size} bytes")
            
            # å°è¯•è¯»å–å¹¶æ˜¾ç¤ºç®€è¦å†…å®¹
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                if 'user_query' in data:
                    print(f"   ğŸ” æŸ¥è¯¢: {data['user_query']}")
                if 'search_stats' in data and 'duration_ms' in data['search_stats']:
                    print(f"   â±ï¸  è€—æ—¶: {data['search_stats']['duration_ms']}ms")
                if 'panel_stats' in data and 'book_title' in data['panel_stats']:
                    print(f"   ğŸ“– ä¹¦ç±: {data['panel_stats']['book_title']}")
                    
            except Exception as e:
                print(f"   âš ï¸ è¯»å–å†…å®¹å¤±è´¥: {e}")
                
            print()
            
        except Exception as e:
            print(f"   âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")

def view_file_content(file_path):
    """æŸ¥çœ‹æŒ‡å®šæ–‡ä»¶çš„è¯¦ç»†å†…å®¹"""
    try:
        path = Path(file_path)
        if not path.exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return
            
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        print(f"ğŸ“„ æ–‡ä»¶å†…å®¹: {path.name}")
        print("=" * 60)
        print(json.dumps(data, ensure_ascii=False, indent=2))
        
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")

def view_daily_summary(target_date=None):
    """æŸ¥çœ‹æŒ‡å®šæ—¥æœŸçš„ç»Ÿè®¡æ€»ç»“"""
    if target_date is None:
        target_date = date.today()
    elif isinstance(target_date, str):
        target_date = datetime.strptime(target_date, '%Y-%m-%d').date()
    
    print(f"ğŸ“… {target_date.strftime('%Y-%m-%d')} çš„ç»Ÿè®¡æ€»ç»“:")
    print("-" * 60)
    
    # ç”Ÿæˆæˆ–è¯»å–æ—¥ç»Ÿè®¡
    daily_file = stats_manager.save_daily_summary(target_date)
    
    try:
        with open(daily_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        daily_stats = data.get('daily_statistics', {})
        summary = daily_stats.get('summary', {})
        
        print(f"ğŸ” æœç´¢ç»Ÿè®¡:")
        print(f"   æ€»æœç´¢æ¬¡æ•°: {daily_stats.get('total_searches', 0)}")
        print(f"   æ€»æœç´¢è€—æ—¶: {summary.get('total_search_duration_ms', 0)}ms")
        print(f"   å¹³å‡æœç´¢è€—æ—¶: {summary.get('average_search_duration_ms', 0):.1f}ms")
        print(f"   å”¯ä¸€æŸ¥è¯¢æ•°: {summary.get('unique_queries', 0)}")
        
        print(f"\nğŸ“– é¢æ¿ç»Ÿè®¡:")
        print(f"   é¢æ¿äº¤äº’æ¬¡æ•°: {daily_stats.get('total_panel_interactions', 0)}")
        print(f"   æ€»é¢æ¿åœç•™æ—¶é•¿: {summary.get('total_panel_duration_ms', 0)}ms")
        print(f"   æŸ¥çœ‹çš„ä¹¦ç±æ•°: {summary.get('unique_books_viewed', 0)}")
        
        print(f"\nğŸ“‹ ä¼šè¯ç»Ÿè®¡:")
        print(f"   æ€»ä¼šè¯æ•°: {daily_stats.get('total_sessions', 0)}")
        
        # æ˜¾ç¤ºæœç´¢è¯¦æƒ…
        if daily_stats.get('search_details'):
            print(f"\nğŸ” æœç´¢è¯¦æƒ…:")
            for i, search in enumerate(daily_stats['search_details'][:5], 1):
                print(f"   {i}. '{search['query']}' - {search['duration_ms']}ms")
        
        # æ˜¾ç¤ºé¢æ¿äº¤äº’è¯¦æƒ…
        if daily_stats.get('panel_details'):
            print(f"\nğŸ“– é¢æ¿äº¤äº’è¯¦æƒ…:")
            for i, panel in enumerate(daily_stats['panel_details'][:5], 1):
                print(f"   {i}. '{panel['book_title']}' - {panel['duration_ms']}ms")
        
    except Exception as e:
        print(f"âŒ è¯»å–æ—¥ç»Ÿè®¡å¤±è´¥: {e}")

def view_comprehensive_report(days=7):
    """æŸ¥çœ‹ç»¼åˆæŠ¥å‘Š"""
    print(f"ğŸ“ˆ æœ€è¿‘{days}å¤©çš„ç»¼åˆæŠ¥å‘Š:")
    print("-" * 60)
    
    report_file = stats_manager.generate_comprehensive_report(days)
    
    try:
        with open(report_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        overall_stats = data.get('overall_statistics', {})
        
        print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡ (æœ€è¿‘{days}å¤©):")
        print(f"   æ€»æœç´¢æ¬¡æ•°: {overall_stats.get('total_searches', 0)}")
        print(f"   æ€»ä¼šè¯æ•°: {overall_stats.get('total_sessions', 0)}")
        print(f"   æ€»é¢æ¿äº¤äº’: {overall_stats.get('total_panel_interactions', 0)}")
        print(f"   æ—¥å‡æœç´¢: {overall_stats.get('average_searches_per_day', 0):.1f}")
        print(f"   æ—¥å‡ä¼šè¯: {overall_stats.get('average_sessions_per_day', 0):.1f}")
        
        print(f"\nğŸ“… æ¯æ—¥è¯¦æƒ…:")
        for day_stats in data.get('daily_summaries', [])[:5]:
            date_str = day_stats.get('date', 'Unknown')
            searches = day_stats.get('total_searches', 0)
            sessions = day_stats.get('total_sessions', 0)
            panels = day_stats.get('total_panel_interactions', 0)
            print(f"   {date_str}: {searches}æ¬¡æœç´¢, {sessions}ä¸ªä¼šè¯, {panels}æ¬¡é¢æ¿äº¤äº’")
        
    except Exception as e:
        print(f"âŒ è¯»å–ç»¼åˆæŠ¥å‘Šå¤±è´¥: {e}")

def list_all_files():
    """åˆ—å‡ºæ‰€æœ‰ç»Ÿè®¡æ–‡ä»¶"""
    print("ğŸ“ æ‰€æœ‰ç»Ÿè®¡æ–‡ä»¶:")
    print("-" * 60)
    
    categories = {
        'search': 'æœç´¢ç»“æœç»Ÿè®¡',
        'panel': 'é¢æ¿äº¤äº’ç»Ÿè®¡', 
        'session': 'ä¼šè¯æ€»ç»“',
        'daily': 'æ—¥ç»Ÿè®¡',
        'report': 'ç»¼åˆæŠ¥å‘Š'
    }
    
    for cat_key, cat_name in categories.items():
        files = stats_manager.list_files_by_type(cat_key)
        print(f"\n{cat_name} ({len(files)}ä¸ªæ–‡ä»¶):")
        
        for file_path in files[-3:]:  # æ˜¾ç¤ºæœ€æ–°çš„3ä¸ª
            mod_time = datetime.fromtimestamp(file_path.stat().st_mtime)
            print(f"   ğŸ“„ {file_path.name} ({mod_time.strftime('%m-%d %H:%M')})")

def main():
    parser = argparse.ArgumentParser(description='äº¤äº’ç»Ÿè®¡æ–‡ä»¶æŸ¥çœ‹å·¥å…·')
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # latest å‘½ä»¤
    latest_parser = subparsers.add_parser('latest', help='æŸ¥çœ‹æœ€æ–°æ–‡ä»¶')
    latest_parser.add_argument('--type', choices=['search', 'panel', 'session', 'daily', 'report'], 
                              help='æ–‡ä»¶ç±»å‹')
    latest_parser.add_argument('--count', type=int, default=5, help='æ˜¾ç¤ºæ–‡ä»¶æ•°é‡')
    
    # view å‘½ä»¤
    view_parser = subparsers.add_parser('view', help='æŸ¥çœ‹æŒ‡å®šæ–‡ä»¶')
    view_parser.add_argument('file_path', help='æ–‡ä»¶è·¯å¾„')
    
    # daily å‘½ä»¤
    daily_parser = subparsers.add_parser('daily', help='æŸ¥çœ‹æ—¥ç»Ÿè®¡')
    daily_parser.add_argument('--date', help='æ—¥æœŸ (YYYY-MM-DDæ ¼å¼ï¼Œé»˜è®¤ä»Šå¤©)')
    
    # report å‘½ä»¤
    report_parser = subparsers.add_parser('report', help='æŸ¥çœ‹ç»¼åˆæŠ¥å‘Š')
    report_parser.add_argument('--days', type=int, default=7, help='æŠ¥å‘Šå¤©æ•°')
    
    # list å‘½ä»¤
    list_parser = subparsers.add_parser('list', help='åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶')
    
    args = parser.parse_args()
    
    if args.command == 'latest':
        view_latest_files(args.type, args.count)
    elif args.command == 'view':
        view_file_content(args.file_path)
    elif args.command == 'daily':
        view_daily_summary(args.date)
    elif args.command == 'report':
        view_comprehensive_report(args.days)
    elif args.command == 'list':
        list_all_files()
    else:
        # é»˜è®¤æ˜¾ç¤ºæœ€æ–°æ–‡ä»¶
        view_latest_files(count=5)
        print("\n" + "="*60)
        print("ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:")
        print("   python view_stats.py latest --type search --count 3")
        print("   python view_stats.py daily --date 2025-06-10")
        print("   python view_stats.py report --days 7")
        print("   python view_stats.py list")

if __name__ == "__main__":
    main()
